Intro
--------------


Abstract
^^^^^^^^^^^^
*The project focuses on the extraction of relevant but hidden data which lies inside lists in Wikipedia pages. The information is unstructured and thus cannot be easily used to form semantic statements and be integrated in the DBpedia ontology. Hence, the main task consists in creating a tool which can take one or more Wikipedia pages with lists within as an input and then construct appropriate mappings to be inserted in a DBpedia dataset. The extractor must prove to work well on a given domain and to have the ability to be expanded to reach generalization.*



General Info
^^^^^^^^^^^^^^^^
I created this project while participating in the `Google Summer of Code <https://summerofcode.withgoogle.com/>`_ program between May and August 2016, for  `DBpedia <http://wiki.dbpedia.org/>`_ .   
You  can have a look at my progress page `here <https://github.com/dbpedia/extraction-framework/wiki/GSoC_2016_Progress_Federica>`_.		
																		
The program is written in Python and is composed of 5 independent modules, for which you can find the description in :doc:`/Modules` section.  The final output consists in a .ttl file containing semantic RDF triples about the lists from a single Wikipedia page or from a class of pages.
Please refer to the `README <https://github.com/dbpedia/list-extractor/blob/master/README.md>`_ file for run instructions. 			
																		
You can also email me at feddiebai@gmail.com for any question or problem.									



