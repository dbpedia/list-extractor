====================
About the Extraction
====================

Depending on the input, the Extractor will analyze a single Wikipedia page or all pages about resources from a given DBpedia ontology class. In both cases, each page is parsed using `JSONpedia <http://jsonpedia.org/frontend/index.html>`_ web service, obtaining a representation of the inner lists, linked to their section and subsection title. At this point, it looks for a mapping suited to the resource class and confronts the section titles to find a match with a list of keywords, depending on the requested language. If a match is found, a related mapping function is applied to each list element to form semantic triples and construct a RDF graph (for example, from a bibliography list of a writer it tries to extract info about his/her works, their literary genre, publication year and isbn code). Finally, if the graph is not empty, all statements are serialized in a .ttl file.

The main concept behind List Extractor is about using the information we have about lists in the Wikipedia page in order to select a suitable rule to form RDF statements. This is very important since the list itself, because of its very nature, doesn't carry any metadata about the information that it is expressing. To overcome this obstacle I have decided to exploit the information carried by the list section title and by the type of resource (obtained from querying a DBpedia SPARQL endpoint). This means that knowing the resource type and analyzing the section title I decide for a certain mapping function to be applied to each list element.

I have explored the domains of **Actors** and **Writers** both in english and italian languages, since I found their lists about filmography and bibliography respectively to be interesting and abundant (before I started coding I did some research about the numerosity of lists in various domains, collaborating with fellow DBpedia GSOCer papalinis for statistics.py, a script useful for both of us included in `Table Extractor <https://github.com/dbpedia/table-extractor>`_). The results have been iteratively refined during these months, and I have provided evaluations obtained by manually analyzing a sample of resources and confronting them with each Wikipedia page, as well as complete datasets that you can find in the `repository <https://github.com/dbpedia/list-extractor>`_. 


+-------------------+--------------+--------------+-----------------------------+
| Topic & Language  | #Resources   | #Statements  | Sample Evaluation 		|  
+===================+==============+==============+=============================+
| Writers IT        |   1'177      |  31'627 	  |`90% <http://goo.gl/7r2P6y>`_|
+-------------------+--------------+--------------+-----------------------------+
| Writers EN        |  29'581      | 302'180      |`79% <http://goo.gl/6OKIRC>`_|
+-------------------+--------------+--------------+-----------------------------+
| Actors IT	    |   1'704      | 110'797      |`94% <http://goo.gl/AwAaP0>`_|
+-------------------+--------------+--------------+-----------------------------+
| Actors EN         |   6'621      | 110'797      |`77% <http://goo.gl/pq0x7i>`_|	
+-------------------+--------------+--------------+-----------------------------+
