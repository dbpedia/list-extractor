**Rules Generator**
===================

**Rules Generator** is a tool that would allow the user to **add new mapping rules** that can be used by the extractor. This tool also allows the user to **create their own mapper functions**, which can be used to extract triples in conjuction with the mapping rules present in ``settings.json``. 

This tool modifies the ``settings.json`` and ``custom_mappers.json`` to store all the mapping rules and the user-defined custom mapping functions.

Usage
-----

``python rulesGenerator.py``

* This is an interactive tool, select the options given in the menu for using the rules generator.
* While creating new mapping rules or mapper functions, make sure to follow the required format as suggested by the tool.
* Upon successful addition/modification, it will update the ``settings.json`` and ``custom_mapper.json`` so that the new user defined rules/functions can run with extractor.

Process
-------

When `Rules Generator` tool is started, it initially loads all the mapping rules currently saved in ``settings.json``, all the dictionaries required by the pre-defined mapper functions from ``mapping_rules.py`` and all the user defined mapper function settings from ``custom_mapper.json``. All the insertions and updates now happen on the most recent settings and the changes are saved after completion.

The prompt screen upon running the tool is

.. code-block:: none
   
   Select one of the following options:

   1. Show existing mapping rules
   2. Show available mapper functions
   3. Add new rules
   4. Add new mapper function
   5. Show custom mapper functions
   0. exit
   Your option: 

Two of the important functions of the rules generator are **3. Add new rules** and **4. Add new mapper function**. The working and structure of both is explained below.

Add new mapping rules
^^^^^^^^^^^^^^^^^^^^^

Adding new mapping rules means adding an entry for a new/existing domain and listing all the mapper functions it should use for the triple generation. The mapper function can be chosen depending on the domain you're focusing on, hence knowledge about the domain is very important. Selection of mapper functions in the mapping rules is important, because simply selecting all the availabe mapper functions to be run on the domain resources might be extremely time and resource consuming, without producing substantial output.

All the mapping rules are stored in ``settings.json``. The structure of the file looks like this:


.. code-block:: python

	{
		"MAPPING": {
			"domain_name_1": ["Mapper-function_1", "Mapper-function_2", "Mapper-function_3".....],
			"domain_name_2": ["Mapper-function_1", "Mapper-function_2", "Mapper-function_3".....],
			...
			...
			...
		}
	}

The ``domain_name`` would contain the domain/class of the resources you want to extract the triples from. For eg. ``Writer``, ``University``, ``MusicalArtist`` etc. You can get a rough idea from `here. <http://mappings.dbpedia.org/server/ontology/classes/>`_

The ``Mapper-function`` would contain one of the mapper function dictionaries present in ``mapping_rules.py``, or the custom mapping rules generated by using rulesGenerator present in ``custom_mappers.json``. For eg. ``BIBLIOGRAPHY``, ``HONORS`` present in ``mapping_rules.py``, or ``MUSIC_GENRE_MAPPER``, present in ``custom_mappers.json``.

Here's an example from the existing ``settings.json``.

.. code-block:: python

	{
		"MAPPING": {
			"Writer": ["BIBLIOGRAPHY", "HONORS", "OTHER_PERSON_DETAILS"],
			"EducationalInstitution": ["ALUMNI", "PROGRAMS_OFFERED", "STAFF"],
			"Actor": ["FILMOGRAPHY", "DISCOGRAPHY", "HONORS"],			
			"MusicalArtist": ["DISCOGRAPHY", "FILMOGRAPHY", "CONCERT_TOURS", "HONORS"],
			"MusicGenre": ["MUSIC_GENRE_MAPPER", "BIBLIOGRAPHY"],			
			"CUSTOM_MUSICAL_ARTIST": ["CUSTOM_ARTIST_MAPPER"],
			"CUSTOM_WRITER": ["CUSTOM_BIBLIOGRAPHY_MAPPER"]
		}
	}


Add new mapper function
^^^^^^^^^^^^^^^^^^^^^^^

Adding a new mapper function involves deciding on how to extract the list-elements from the Wikipedia resource, and once extracted, how to map them to form the appropriate RDF triples. Again, the knowledge about the domain is very necessary, as choosing the section and subsection headers are the key for writing the mapper functions. All the custom mapper functions are stored in ``custom_mappers.json``. Here's the skeletal structure of the file:

.. code-block:: python

	{
		"mapper_function_name": {
			"headers": {
				"lang_1": ["header_1", "header_2", ....],
				"lang_2": ["header_1", "header_2", ....],
				...
				...
			},
			"extractors": [1, 2, 3, 4],  #at least one out of the four is required.
			"ontology": {
				"lang_1": {
					"subsection/property string_1": "dbo:property",
					"subsection/property string_2": "dbo:property",
					..
					..
				},
				"lang_2": {
					"subsection/property string_1": "dbo:property",
					"subsection/property string_2": "dbo:property",
					..
					..
				}
				...
				...
				...
			},
			"years": "Yes"   #boolean: Yes/No
		},
		....
		....
		....
	}

Here, there are 4 key entries each mapper function: ``headers``, ``extractors``, ``ontology`` and ``years``. Since the list-extractor supports different languages, the rules generator also provides entries in several languages for ``headers`` and ``ontology``.

The first entry, ``headers``, consists of ``string`` values for all the possible values for section headers that contain the list elements in the Wikipedia resource. Since many section headers might mean same things (possibly synonyms), this is a ``list`` of ``string`` values. The mapper function would only look for the list-elements which come under he sections provided in ``headers``.

The second entry, ``extractors``, is a ``list of integers``, which contains the integer values corresponding to the extractors that are to be used to extract out information from the raw list elements. There are 4 extractors that list-extractor provides:

* **Italic Mapper**: Extracts `italic text` inside the list element, mapped by ``''..''`` in Wikipedia. This is the first mapping to be applied since it's very precise. If this fails, more general mappings can be applied. Add ``1`` in the ``extractors`` list to use this extractor.
 
* **Reference Mapper**: Looks for a `reference` inside the element, which has been marked with ``{{...}}`` by ``wikiParser``. Once a reference is found, that URI is used for mapping. Add ``2`` in the ``extractors`` list to use this extractor.

* **Quote Mapper**: Looks for a `quotation marks` inside the element and returns the string inside quotes. This is not a very precise mapper, but can prove useful at many places. Add ``3`` in the ``extractors`` list to use this extractor.

* **General Mapper**: The worst case extractor, can be called when other extractors fail. It extracts all text different from lists until a punctuation mark is found. Applies a regex to find the main concept and cuts off numbers and punctuation marks. Generally not very precise and reliable. Add ``4`` in the ``extractors`` list to use this extractor.

`The extractors can be chosen w.r.t the needs. For a more precise, less noisy triple generations, one can use only the first 2 extractors. On the other hand, if you're okay with some bad triples, you can select all 4 extractors, which will generate more triples by including the less reliable extractors, but the noise will also increase.`

The third entry, ``ontology``, consists of ``key-value`` pairs, which are used for selecting the mapping rules in the RDF triples. The ``key`` is the ``string`` present in the wiki resource's section/subsection/list-element entry which determines the property of the mapping to be done, and ``value`` is the corresponding entry in the dbpedia ontology. The RDF triples are mapped using these values, corresponding to the DBpedia ontology values.

The fourth entry, ``years``, is just a ``boolean`` value, which determines wether to look for time-periods in the list-elements in the resources or not. Selecting ``Yes`` would mean the mapper function will generate triples related to dates. 

All these entries are used by ``mapper.map_user_defined_mappings()`` to form a working mapper function.

Here's an example from the existing ``custom_mappers.json``.

.. code-block:: python

	{
		"CUSTOM_ARTIST_MAPPER": {
			"headers": {
				"en": ["Discography", "Tours"]
			},
			"extractors": [1, 2, 3, 4],
			"ontology": {
				"en": {
					"tours": "concertTour",
					"discography": "musicalArtist"
				}
			},
			"years": "Yes"
		},
		"MUSIC_GENRE_MAPPER": {
			"headers": {
				"en": ["bands", "artists"]
			},
			"extractors": [1, 2, 3, 4],
			"ontology": {
				"en": {
					"default": "notableArtist",
					"artist": "notableArtist",
					"band": "notableBand",
					"Subgenre" : "SubGenre",
					"division" : "SubGenre",
					"festivals" : "relatedFestivals"
				}
			},
			"years": "Yes"
		}
	}

